{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting imbalanced-learnNote: you may need to restart the kernel to use updated packages.\n",
      "  Downloading imbalanced_learn-0.7.0-py3-none-any.whl (167 kB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Error parsing requirements for tensorflow: [Errno 2] No such file or directory: 'd:\\\\installation\\\\anaconda3\\\\lib\\\\site-packages\\\\tensorflow-2.1.0.dist-info\\\\METADATA'\n",
      "WARNING: Error parsing requirements for rsa: [Errno 2] No such file or directory: 'd:\\\\installation\\\\anaconda3\\\\lib\\\\site-packages\\\\rsa-4.0.dist-info\\\\METADATA'\n",
      "WARNING: Error parsing requirements for google-pasta: [Errno 2] No such file or directory: 'd:\\\\installation\\\\anaconda3\\\\lib\\\\site-packages\\\\google_pasta-0.2.0.dist-info\\\\METADATA'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Requirement already satisfied: numpy>=1.13.3 in d:\\installation\\anaconda3\\lib\\site-packages (from imbalanced-learn) (1.19.4)\n",
      "Requirement already satisfied: scikit-learn>=0.23 in d:\\installation\\anaconda3\\lib\\site-packages (from imbalanced-learn) (0.23.2)\n",
      "Requirement already satisfied: scipy>=0.19.1 in d:\\installation\\anaconda3\\lib\\site-packages (from imbalanced-learn) (1.5.4)\n",
      "Requirement already satisfied: joblib>=0.11 in d:\\installation\\anaconda3\\lib\\site-packages (from imbalanced-learn) (0.16.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in d:\\installation\\anaconda3\\lib\\site-packages (from scikit-learn>=0.23->imbalanced-learn) (2.1.0)\n",
      "Installing collected packages: imbalanced-learn\n",
      "Successfully installed imbalanced-learn-0.7.0\n"
     ]
    }
   ],
   "source": [
    "!pip install imbalanced-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')\n",
    "import imblearn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "#모델링 함수\n",
    "def modeling(model,x_train,x_test,y_train,y_test):\n",
    "    model.fit(x_train,y_train)\n",
    "    pred = model.predict(x_test)\n",
    "    metrics(y_test,pred)\n",
    "\n",
    "#평가 지표\n",
    "def metrics(y_test,pred):\n",
    "    accuracy = accuracy_score(y_test,pred)\n",
    "    precision = precision_score(y_test,pred)\n",
    "    recall = recall_score(y_test,pred)    \n",
    "    #print('정확도 : {0:.4f}, 정밀도 : {1:.4f}, 재현율 : {2:.4f}'.format(accuracy,precision,recall))\n",
    "    print(\"최종 : {}\".format((recall*0.5 + accuracy*0.5)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataload/Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# uci-secom.csv를 이용해 Pass/Fail를 예측하는 모델을 만든후\n",
    "data = pd.read_csv(\"data/uci-secom.csv\")\n",
    "# 결측치 0으로\n",
    "data = data.replace(np.NaN, 0)\n",
    "# Time 열 제거\n",
    "data = data.drop(columns = ['Time'], axis = 1)\n",
    "\n",
    "#----preprocessing----\n",
    "x = data.drop(columns = ['Pass/Fail'], axis = 1)\n",
    "y = data['Pass/Fail'].to_numpy().ravel()\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, random_state = 0)\n",
    "# StandardScaler\n",
    "sc = StandardScaler()\n",
    "x_train = sc.fit_transform(x_train)\n",
    "x_test = sc.transform(x_test)\n",
    "\n",
    "# Sampling\n",
    "smote = SMOTE(random_state=0)\n",
    "ros = RandomOverSampler()\n",
    "rus = RandomUnderSampler()\n",
    "#fit_resample\n",
    "x_train_smote,y_train_smote = smote.fit_sample(x_train,y_train)\n",
    "x_train_ros,y_train_ros = ros.fit_resample(x_train,y_train)\n",
    "x_train_rus,y_train_rus = rus.fit_resample(x_train,y_train)\n",
    "\n",
    "# oversampled_data = pd.DataFrame(oversampled_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1253 2324 2324 182\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape[0],x_train_smote.shape[0],x_train_ros.shape[0],x_train_rus.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "import xgboost as xgb\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "\n",
    "models = []\n",
    "models.append(('LR', LogisticRegression(max_iter =5000))) #로지스틱 회귀모델 \n",
    "models.append(('LDA', LinearDiscriminantAnalysis()))  # LDA 모델\n",
    "models.append(('KNN', KNeighborsClassifier()))  # KNN 모델\n",
    "models.append(('CART', DecisionTreeClassifier()))  # 의사결정트리 모델\n",
    "models.append(('NB', GaussianNB()))  # 가우시안 나이브 베이즈 모델\n",
    "models.append(('RF', RandomForestClassifier()))  # 랜덤포레스트 모델\n",
    "models.append(('SVM', SVC(gamma='auto')))  # SVM 모델\n",
    "models.append(('XGB', XGBClassifier()))  # XGB 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('LR', LogisticRegression(max_iter=5000)),\n",
       " ('LDA', LinearDiscriminantAnalysis()),\n",
       " ('KNN', KNeighborsClassifier()),\n",
       " ('CART', DecisionTreeClassifier()),\n",
       " ('NB', GaussianNB()),\n",
       " ('RF', RandomForestClassifier()),\n",
       " ('SVM', SVC(gamma='auto')),\n",
       " ('XGB',\n",
       "  XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
       "                colsample_bynode=None, colsample_bytree=None, gamma=None,\n",
       "                gpu_id=None, importance_type='gain', interaction_constraints=None,\n",
       "                learning_rate=None, max_delta_step=None, max_depth=None,\n",
       "                min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "                n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
       "                random_state=None, reg_alpha=None, reg_lambda=None,\n",
       "                scale_pos_weight=None, subsample=None, tree_method=None,\n",
       "                validate_parameters=None, verbosity=None))]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR\n",
      "최종 : 47.795198432141106\n",
      "LDA\n",
      "최종 : 56.76139147476727\n",
      "KNN\n",
      "최종 : 47.92993630573248\n",
      "CART\n",
      "최종 : 48.59137677609016\n",
      "NB\n",
      "최종 : 46.10485056344929\n",
      "RF\n",
      "최종 : 47.92993630573248\n",
      "SVM\n",
      "최종 : 47.92993630573248\n",
      "XGB\n",
      "최종 : 47.77070063694268\n"
     ]
    }
   ],
   "source": [
    "# original\n",
    "for i in range(len(models)):\n",
    "    model = models[i][-1]\n",
    "    print(models[i][0])\n",
    "    modeling(model, x_train ,x_test, y_train ,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR\n",
      "최종 : 44.928956393924544\n",
      "LDA\n",
      "최종 : 51.028907398334155\n",
      "KNN\n",
      "최종 : 53.74816266536012\n",
      "CART\n",
      "최종 : 45.565899069083784\n",
      "NB\n",
      "최종 : 50.40421362077413\n",
      "RF\n",
      "최종 : 47.452229299363054\n",
      "SVM\n",
      "최종 : 49.54679078882901\n",
      "XGB\n",
      "최종 : 50.979911807937285\n"
     ]
    }
   ],
   "source": [
    "# smote\n",
    "for i in range(len(models)):\n",
    "    model = models[i][-1]\n",
    "    print(models[i][0])\n",
    "    modeling(model, x_train_smote, x_test, y_train_smote, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR\n",
      "최종 : 48.615874571288586\n",
      "LDA\n",
      "최종 : 50.55120039196473\n",
      "KNN\n",
      "최종 : 44.13277804997551\n",
      "CART\n",
      "최종 : 43.94904458598726\n",
      "NB\n",
      "최종 : 46.58255756981872\n",
      "RF\n",
      "최종 : 47.92993630573248\n",
      "SVM\n",
      "최종 : 45.85987261146497\n",
      "XGB\n",
      "최종 : 51.45761881430671\n"
     ]
    }
   ],
   "source": [
    "# ros\n",
    "for i in range(len(models)):\n",
    "    model = models[i][-1]\n",
    "    print(models[i][0])\n",
    "    modeling(model, x_train_ros, x_test, y_train_ros, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR\n",
      "최종 : 54.44634982851544\n",
      "LDA\n",
      "최종 : 53.650171484566386\n",
      "KNN\n",
      "최종 : 49.644781969622734\n",
      "CART\n",
      "최종 : 58.45173934345909\n",
      "NB\n",
      "최종 : 54.05438510534052\n",
      "RF\n",
      "최종 : 61.954924056834884\n",
      "SVM\n",
      "최종 : 63.54728074473297\n",
      "XGB\n",
      "최종 : 62.77560019598236\n"
     ]
    }
   ],
   "source": [
    "# rus\n",
    "for i in range(len(models)):\n",
    "    model = models[i][-1]\n",
    "    print(models[i][0])\n",
    "    modeling(model, x_train_rus, x_test, y_train_rus, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gridsearch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "clf1 = DecisionTreeClassifier(max_depth=4)\n",
    "clf2 = KNeighborsClassifier(n_neighbors=7)\n",
    "clf3 = SVC(kernel='rbf', probability=True)\n",
    "\n",
    "models.append(('RF', RandomForestClassifier()))  # 랜덤포레스트 모델\n",
    "models.append(('SVM', SVC(gamma='auto')))  # SVM 모델\n",
    "models.append(('XGB', XGBClassifier()))  # XGB 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['bootstrap', 'ccp_alpha', 'class_weight', 'criterion', 'max_depth', 'max_features', 'max_leaf_nodes', 'max_samples', 'min_impurity_decrease', 'min_impurity_split', 'min_samples_leaf', 'min_samples_split', 'min_weight_fraction_leaf', 'n_estimators', 'n_jobs', 'oob_score', 'random_state', 'verbose', 'warm_start'])\n",
      "\n",
      "dict_keys(['objective', 'base_score', 'booster', 'colsample_bylevel', 'colsample_bynode', 'colsample_bytree', 'gamma', 'gpu_id', 'importance_type', 'interaction_constraints', 'learning_rate', 'max_delta_step', 'max_depth', 'min_child_weight', 'missing', 'monotone_constraints', 'n_estimators', 'n_jobs', 'num_parallel_tree', 'random_state', 'reg_alpha', 'reg_lambda', 'scale_pos_weight', 'subsample', 'tree_method', 'validate_parameters', 'verbosity'])\n",
      "\n",
      "dict_keys(['C', 'break_ties', 'cache_size', 'class_weight', 'coef0', 'decision_function_shape', 'degree', 'gamma', 'kernel', 'max_iter', 'probability', 'random_state', 'shrinking', 'tol', 'verbose'])\n"
     ]
    }
   ],
   "source": [
    "model1 = RandomForestClassifier()\n",
    "print(model1.get_params().keys())\n",
    "print()\n",
    "model2 = XGBClassifier()\n",
    "print(model2.get_params().keys())\n",
    "print()\n",
    "model3 = SVC()\n",
    "print(model3.get_params().keys())\n",
    "#parameters = {'C': [0.001, 0.01, 0.1], 'penalty': ['l1', 'l2']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "params1 = {'max_depth':[1, 10, 100], 'max_features':[1, 10, 100], 'random_state':[0, 1]}\n",
    "# params2 = {'gamma':[0.5,1,3,5], 'n_neighbors':[13,14, 15]}\n",
    "# params3 = {'gamma':[\"auto\", \"scale\"], 'degree':[1, 2, 3], 'random_state':[0, 1]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6273885350318471\n",
      "{'max_depth': 100, 'max_features': 10, 'random_state': 1}\n",
      "0.5384615384615384\n",
      "{'max_depth': 1, 'max_features': 1, 'random_state': 0}\n"
     ]
    }
   ],
   "source": [
    "GS11 = GridSearchCV(model1, params1, scoring = 'accuracy', cv = 5)\n",
    "GS11.fit(x_train_rus, y_train_rus)\n",
    "model1_acc = GS11.score(x_test, y_test)\n",
    "print(model1_acc)\n",
    "print(GS11.best_params_)\n",
    "\n",
    "GS12 = GridSearchCV(model1, params1, scoring = 'recall', cv = 5)\n",
    "GS12.fit(x_train_rus, y_train_rus)\n",
    "model1_rec = GS12.score(x_test, y_test)\n",
    "print(model1_rec)\n",
    "print(GS12.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.767515923566879\n",
      "{'leaf_size': 1, 'n_neighbors': 14}\n",
      "0.46153846153846156\n",
      "{'leaf_size': 1, 'n_neighbors': 13}\n"
     ]
    }
   ],
   "source": [
    "GS21 = GridSearchCV(model2, params2, scoring = 'accuracy', cv = 5)\n",
    "GS21.fit(x_train_rus, y_train_rus)\n",
    "model2_acc = GS21.score(x_test, y_test)\n",
    "print(model2_acc)\n",
    "print(GS21.best_params_)\n",
    "\n",
    "GS22 = GridSearchCV(model2, params2, scoring = 'recall', cv = 5)\n",
    "GS22.fit(x_train_rus, y_train_rus)\n",
    "model2_rec = GS22.score(x_test, y_test)\n",
    "print(model2_rec)\n",
    "print(GS22.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.732484076433121\n",
      "{'degree': 1, 'gamma': 'auto', 'random_state': 0}\n",
      "0.6153846153846154\n",
      "{'degree': 1, 'gamma': 'scale', 'random_state': 0}\n"
     ]
    }
   ],
   "source": [
    "GS31 = GridSearchCV(model3, params3, scoring = 'accuracy', cv = 5)\n",
    "GS31.fit(x_train_rus, y_train_rus)\n",
    "model3_acc = GS31.score(x_test, y_test)\n",
    "print(model3_acc)\n",
    "print(GS31.best_params_)\n",
    "\n",
    "GS32 = GridSearchCV(model3, params3, scoring = 'recall', cv = 5)\n",
    "GS32.fit(x_train_rus, y_train_rus)\n",
    "model3_rec = GS32.score(x_test, y_test)\n",
    "print(model3_rec)\n",
    "print(GS32.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.metrics import fbeta_score, make_scorer\n",
    "clf1 = LogisticRegression(random_state=1)\n",
    "clf2 = RandomForestClassifier(random_state=1)\n",
    "clf3 = GaussianNB()\n",
    "eclf = VotingClassifier(estimators=[('lr', clf1), ('rf', clf2), ('gnb', clf3)],voting='soft')\n",
    "\n",
    "params = {'lr__C': [1.0, 100.0], 'rf__n_estimators': [20, 200]}\n",
    "\n",
    "grid = GridSearchCV(estimator=eclf, param_grid=params, scoring=['accuracy', 'recall'], cv=5)\n",
    "\n",
    "grid.fit(x_train_rus,y_train_rus)\n",
    "pred = grid.predict(x_test)\n",
    "metrics(y_test,pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from itertools import product\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "#clf1 = DecisionTreeClassifier(max_depth=18, max_features=95, random_state=0)\n",
    "clf1 = DecisionTreeClassifier()\n",
    "#clf2 = KNeighborsClassifier(leaf_size=1, n_neighbors=14)\n",
    "clf2 = KNeighborsClassifier()\n",
    "#clf3 = SVC(degree=1, gamma='auto', random_state=0, probability=True)\n",
    "clf3 = SVC(probability=True)\n",
    "clf4 = XGBClassifier()\n",
    "#clf5 = RandomForestClassifier(max_depth=100, max_features=10, random_state=1)\n",
    "clf5 = RandomForestClassifier()\n",
    "\n",
    "eclf = VotingClassifier(estimators=[('dt', clf1), ('knn', clf2), ('svc', clf3), ('xgb', clf4), ('rfc', clf5)],\n",
    "                        voting='soft',\n",
    "                        weights=[1, 50, 100, 100,50])\n",
    "\n",
    "#clf1 = clf1.fit(x_train_ros,y_train_ros)\n",
    "#clf2 = clf2.fit(x_train_ros,y_train_ros)\n",
    "#clf3 = clf3.fit(x_train_ros,y_train_ros)\n",
    "#clf4 = clf4.fit(x_train_ros,y_train_ros)\n",
    "#clf5 = clf5.fit(x_train_ros,y_train_ros)\n",
    "#eclf = eclf.fit(x_train_ros,y_train_ros)\n",
    "\n",
    "clf1 = clf1.fit(x_train_smote,y_train_smote)\n",
    "clf2 = clf2.fit(x_train_smote,y_train_smote)\n",
    "clf3 = clf3.fit(x_train_smote,y_train_smote)\n",
    "clf4 = clf4.fit(x_train_rus,y_train_rus)\n",
    "clf5 = clf5.fit(x_train_smote,y_train_smote)\n",
    "eclf = eclf.fit(x_train_smote,y_train_smote)\n",
    "\n",
    "#clf1 = clf1.fit(x_train,y_train)\n",
    "#clf2 = clf2.fit(x_train,y_train)\n",
    "#clf3 = clf3.fit(x_train,y_train)\n",
    "#clf4 = clf4.fit(x_train,y_train)\n",
    "#clf5 = clf5.fit(x_train,y_train)\n",
    "#eclf = eclf.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "최종 : 47.29299363057325\n"
     ]
    }
   ],
   "source": [
    "pred = eclf.predict(x_test)\n",
    "metrics(y_test,pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>580</th>\n",
       "      <th>581</th>\n",
       "      <th>582</th>\n",
       "      <th>583</th>\n",
       "      <th>584</th>\n",
       "      <th>585</th>\n",
       "      <th>586</th>\n",
       "      <th>587</th>\n",
       "      <th>588</th>\n",
       "      <th>589</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2008-11-09 15:05:00</td>\n",
       "      <td>2958.83</td>\n",
       "      <td>2488.50</td>\n",
       "      <td>2197.5222</td>\n",
       "      <td>1373.0077</td>\n",
       "      <td>1.1369</td>\n",
       "      <td>100.0</td>\n",
       "      <td>106.0733</td>\n",
       "      <td>0.1240</td>\n",
       "      <td>1.3886</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.4975</td>\n",
       "      <td>0.0142</td>\n",
       "      <td>0.0031</td>\n",
       "      <td>2.8592</td>\n",
       "      <td>0.0246</td>\n",
       "      <td>0.0064</td>\n",
       "      <td>0.0022</td>\n",
       "      <td>25.9900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2008-10-14 03:21:00</td>\n",
       "      <td>3073.57</td>\n",
       "      <td>2528.59</td>\n",
       "      <td>2217.4111</td>\n",
       "      <td>1032.2836</td>\n",
       "      <td>1.4802</td>\n",
       "      <td>100.0</td>\n",
       "      <td>101.3511</td>\n",
       "      <td>0.1195</td>\n",
       "      <td>1.4234</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.4950</td>\n",
       "      <td>0.0115</td>\n",
       "      <td>0.0028</td>\n",
       "      <td>2.3235</td>\n",
       "      <td>0.0138</td>\n",
       "      <td>0.0162</td>\n",
       "      <td>0.0047</td>\n",
       "      <td>117.7603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2008-09-24 10:10:00</td>\n",
       "      <td>2995.73</td>\n",
       "      <td>2515.83</td>\n",
       "      <td>2231.6111</td>\n",
       "      <td>2005.8966</td>\n",
       "      <td>1.2969</td>\n",
       "      <td>100.0</td>\n",
       "      <td>93.7522</td>\n",
       "      <td>0.1234</td>\n",
       "      <td>1.4136</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0047</td>\n",
       "      <td>183.3928</td>\n",
       "      <td>0.5011</td>\n",
       "      <td>0.0103</td>\n",
       "      <td>0.0027</td>\n",
       "      <td>2.0617</td>\n",
       "      <td>0.0090</td>\n",
       "      <td>0.0166</td>\n",
       "      <td>0.0047</td>\n",
       "      <td>183.3928</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 591 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Time        0        1          2          3       4      5  \\\n",
       "0  2008-11-09 15:05:00  2958.83  2488.50  2197.5222  1373.0077  1.1369  100.0   \n",
       "1  2008-10-14 03:21:00  3073.57  2528.59  2217.4111  1032.2836  1.4802  100.0   \n",
       "2  2008-09-24 10:10:00  2995.73  2515.83  2231.6111  2005.8966  1.2969  100.0   \n",
       "\n",
       "          6       7       8  ...     580       581     582     583     584  \\\n",
       "0  106.0733  0.1240  1.3886  ...     NaN       NaN  0.4975  0.0142  0.0031   \n",
       "1  101.3511  0.1195  1.4234  ...     NaN       NaN  0.4950  0.0115  0.0028   \n",
       "2   93.7522  0.1234  1.4136  ...  0.0047  183.3928  0.5011  0.0103  0.0027   \n",
       "\n",
       "      585     586     587     588       589  \n",
       "0  2.8592  0.0246  0.0064  0.0022   25.9900  \n",
       "1  2.3235  0.0138  0.0162  0.0047  117.7603  \n",
       "2  2.0617  0.0090  0.0166  0.0047  183.3928  \n",
       "\n",
       "[3 rows x 591 columns]"
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# manufacture_test_feature.csv의 Pass/Fail를 예측해보세요.\n",
    "dataframe = pd.read_csv(\"data/manufacture_test_feature.csv\")\n",
    "# manufacture_test_feature.csv의 순서대로 [index, Pass/Fail]를 가지는 dataframe을\n",
    "dataframe.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe = dataframe.replace(np.NaN, 0)\n",
    "# Time 열 제거\n",
    "dataframe = dataframe.drop(columns = ['Time'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(314, 590)"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>580</th>\n",
       "      <th>581</th>\n",
       "      <th>582</th>\n",
       "      <th>583</th>\n",
       "      <th>584</th>\n",
       "      <th>585</th>\n",
       "      <th>586</th>\n",
       "      <th>587</th>\n",
       "      <th>588</th>\n",
       "      <th>589</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2958.83</td>\n",
       "      <td>2488.50</td>\n",
       "      <td>2197.5222</td>\n",
       "      <td>1373.0077</td>\n",
       "      <td>1.1369</td>\n",
       "      <td>100.0</td>\n",
       "      <td>106.0733</td>\n",
       "      <td>0.1240</td>\n",
       "      <td>1.3886</td>\n",
       "      <td>0.0107</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.4975</td>\n",
       "      <td>0.0142</td>\n",
       "      <td>0.0031</td>\n",
       "      <td>2.8592</td>\n",
       "      <td>0.0246</td>\n",
       "      <td>0.0064</td>\n",
       "      <td>0.0022</td>\n",
       "      <td>25.9900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3073.57</td>\n",
       "      <td>2528.59</td>\n",
       "      <td>2217.4111</td>\n",
       "      <td>1032.2836</td>\n",
       "      <td>1.4802</td>\n",
       "      <td>100.0</td>\n",
       "      <td>101.3511</td>\n",
       "      <td>0.1195</td>\n",
       "      <td>1.4234</td>\n",
       "      <td>-0.0045</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.4950</td>\n",
       "      <td>0.0115</td>\n",
       "      <td>0.0028</td>\n",
       "      <td>2.3235</td>\n",
       "      <td>0.0138</td>\n",
       "      <td>0.0162</td>\n",
       "      <td>0.0047</td>\n",
       "      <td>117.7603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2995.73</td>\n",
       "      <td>2515.83</td>\n",
       "      <td>2231.6111</td>\n",
       "      <td>2005.8966</td>\n",
       "      <td>1.2969</td>\n",
       "      <td>100.0</td>\n",
       "      <td>93.7522</td>\n",
       "      <td>0.1234</td>\n",
       "      <td>1.4136</td>\n",
       "      <td>0.0129</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0047</td>\n",
       "      <td>183.3928</td>\n",
       "      <td>0.5011</td>\n",
       "      <td>0.0103</td>\n",
       "      <td>0.0027</td>\n",
       "      <td>2.0617</td>\n",
       "      <td>0.0090</td>\n",
       "      <td>0.0166</td>\n",
       "      <td>0.0047</td>\n",
       "      <td>183.3928</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 590 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0        1          2          3       4      5         6       7  \\\n",
       "0  2958.83  2488.50  2197.5222  1373.0077  1.1369  100.0  106.0733  0.1240   \n",
       "1  3073.57  2528.59  2217.4111  1032.2836  1.4802  100.0  101.3511  0.1195   \n",
       "2  2995.73  2515.83  2231.6111  2005.8966  1.2969  100.0   93.7522  0.1234   \n",
       "\n",
       "        8       9  ...     580       581     582     583     584     585  \\\n",
       "0  1.3886  0.0107  ...  0.0000    0.0000  0.4975  0.0142  0.0031  2.8592   \n",
       "1  1.4234 -0.0045  ...  0.0000    0.0000  0.4950  0.0115  0.0028  2.3235   \n",
       "2  1.4136  0.0129  ...  0.0047  183.3928  0.5011  0.0103  0.0027  2.0617   \n",
       "\n",
       "      586     587     588       589  \n",
       "0  0.0246  0.0064  0.0022   25.9900  \n",
       "1  0.0138  0.0162  0.0047  117.7603  \n",
       "2  0.0090  0.0166  0.0047  183.3928  \n",
       "\n",
       "[3 rows x 590 columns]"
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe = sc.transform(dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_preds = eclf.predict(dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,  1,\n",
       "       -1, -1, -1, -1,  1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "       -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "       -1, -1, -1, -1, -1, -1, -1, -1,  1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "       -1, -1, -1, -1, -1, -1,  1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "       -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "        1, -1, -1, -1, -1,  1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "       -1,  1, -1, -1, -1, -1, -1,  1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "        1, -1,  1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,  1,\n",
       "       -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "       -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "       -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "       -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "       -1, -1, -1,  1, -1, -1, -1, -1, -1,  1,  1, -1, -1, -1, -1, -1, -1,\n",
       "       -1, -1, -1, -1, -1, -1, -1, -1,  1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "       -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "       -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,  1, -1, -1, -1, -1, -1, -1,\n",
       "       -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "       -1, -1, -1,  1, -1, -1, -1, -1], dtype=int64)"
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>309</th>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>310</th>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>311</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>312</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>313</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>314 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     0\n",
       "0    1\n",
       "1   -1\n",
       "2   -1\n",
       "3    1\n",
       "4    1\n",
       "..  ..\n",
       "309 -1\n",
       "310 -1\n",
       "311  1\n",
       "312  1\n",
       "313  1\n",
       "\n",
       "[314 rows x 1 columns]"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(model_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.kaggle.com/rafjaa/resampling-strategies-for-imbalanced-datasets\n",
    "\n",
    "https://joonable.tistory.com/27\n",
    "\n",
    "* test 데이터는 모른다는 게 가정이기 때문입니다. fit 단계에서 데이터 전체의 평균과 분산을 이용하는데 test 데이터는 이걸 알 수 없기 때문에 기존 train 데이터의 평균과 분산을 이용해 정규화 합니다. 그래서 test에서 transform만 수행합니다.\n",
    "* 추가적인 설명으로는, 학습데이터 세트에서 변환을 위한 기반 설정(예를 들어 학습 데이터 세트의 최대값/최소값등)을 먼저 fit()을 통해서 설정한 뒤에 이를 기반으로 학습 데이터의 transform()을 수행하되 학습 데이터에서 설정된 변환을 위한 기반 설정을 그대로 테스트 데이터에도 적용하기 위해서입니다.\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html\n",
    "\n",
    "https://m.blog.naver.com/PostView.nhn?blogId=gustn3964&logNo=221431933811&proxyReferer=https:%2F%2Fwww.google.com%2F\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
