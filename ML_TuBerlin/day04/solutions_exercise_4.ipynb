{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "dafef955-4c2c-a871-f1d8-3e0d306393b0"
   },
   "source": [
    "# Exercise 4: Breast cancer classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercises:\n",
    "---\n",
    "### 1. Preprocessing:\n",
    "\n",
    "    1.1 Drop the \"id\" column and drop \"Unnamed\" column\n",
    "    1.2 Replace the label \"diagnosis\" with binary labels, where \"M\"(Malignant)=1, and \"B\"(=Benign)=0.\n",
    "    1.3 Split the dataset into a training set(=80% of the data) and a test set(=20% of the data). Shuffle the data.\n",
    "    1.4 For both datasets, split it into a dataset with only features: \"X\" and one another containing only the labels: \"Y\".\n",
    "\n",
    "### 2. Implementation and training of the models:\n",
    "    2.1 Implement and train a Logistic Regression model on the training set using SkLearn. Use the default arguments for the model. \n",
    "    2.2 Implementand train a Decision Tree model on the training set using SkLearn. Use the default arguments for the model.\n",
    "    2.3 Evaluate the test accuracy of both models on the test set, which one is better ?\n",
    "    2.4 Are we overfitting for one of the models ? \n",
    "\n",
    "### 3. Playing with different features and Hyperparameters\n",
    "    3.1 Train both the Logistic Regression AND the Decision Tree model using only the following features:\n",
    "    'radius_mean','perimeter_mean','area_mean','compactness_mean','concave points_mean'.\n",
    "    \n",
    "    3.2 Compare the test accuracy results with the models from 2 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "5e26372e-f1bd-b50f-0c1c-33a44306d1f7"
   },
   "source": [
    "# 0. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "2768ce80-1a7d-ca31-a35f-29cf0ef7fb15"
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "\n",
    "%matplotlib inline \n",
    "import matplotlib.pyplot as plt # side-stepping mpl backend\n",
    "import matplotlib.gridspec as gridspec # subplots\n",
    "#import mpld3 as mpl\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier, export_graphviz\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "09b9d090-2cba-ad5a-58ce-84208f95dba4"
   },
   "source": [
    "# 1. Load and preprocess the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_cell_guid": "9180cb22-53d2-6bf2-3a29-99448ab808fb"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "      <th>Unnamed: 32</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>842302</td>\n",
       "      <td>M</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>...</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>842517</td>\n",
       "      <td>M</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>...</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>84300903</td>\n",
       "      <td>M</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>...</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>84348301</td>\n",
       "      <td>M</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>...</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>84358402</td>\n",
       "      <td>M</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>...</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
       "0    842302         M        17.99         10.38          122.80     1001.0   \n",
       "1    842517         M        20.57         17.77          132.90     1326.0   \n",
       "2  84300903         M        19.69         21.25          130.00     1203.0   \n",
       "3  84348301         M        11.42         20.38           77.58      386.1   \n",
       "4  84358402         M        20.29         14.34          135.10     1297.0   \n",
       "\n",
       "   smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
       "0          0.11840           0.27760          0.3001              0.14710   \n",
       "1          0.08474           0.07864          0.0869              0.07017   \n",
       "2          0.10960           0.15990          0.1974              0.12790   \n",
       "3          0.14250           0.28390          0.2414              0.10520   \n",
       "4          0.10030           0.13280          0.1980              0.10430   \n",
       "\n",
       "   ...  texture_worst  perimeter_worst  area_worst  smoothness_worst  \\\n",
       "0  ...          17.33           184.60      2019.0            0.1622   \n",
       "1  ...          23.41           158.80      1956.0            0.1238   \n",
       "2  ...          25.53           152.50      1709.0            0.1444   \n",
       "3  ...          26.50            98.87       567.7            0.2098   \n",
       "4  ...          16.67           152.20      1575.0            0.1374   \n",
       "\n",
       "   compactness_worst  concavity_worst  concave points_worst  symmetry_worst  \\\n",
       "0             0.6656           0.7119                0.2654          0.4601   \n",
       "1             0.1866           0.2416                0.1860          0.2750   \n",
       "2             0.4245           0.4504                0.2430          0.3613   \n",
       "3             0.8663           0.6869                0.2575          0.6638   \n",
       "4             0.2050           0.4000                0.1625          0.2364   \n",
       "\n",
       "   fractal_dimension_worst  Unnamed: 32  \n",
       "0                  0.11890          NaN  \n",
       "1                  0.08902          NaN  \n",
       "2                  0.08758          NaN  \n",
       "3                  0.17300          NaN  \n",
       "4                  0.07678          NaN  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"data/breast_cancer.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "e382010d-1d71-b8d6-4a6e-a0abc9e42372"
   },
   "source": [
    "### Solutions 1.1-1.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_cell_guid": "f9fd3701-af9d-8d8c-5d0e-e2673d7977fe"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "569"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop('id',axis=1, inplace=True)\n",
    "df.drop('Unnamed: 32',axis=1, inplace=True)\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_cell_guid": "0882e4c2-3d4d-d4d9-5f49-f36c1b248b93",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>symmetry_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>...</td>\n",
       "      <td>25.38</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>...</td>\n",
       "      <td>24.99</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>...</td>\n",
       "      <td>23.57</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>...</td>\n",
       "      <td>14.91</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>...</td>\n",
       "      <td>22.54</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
       "0          1        17.99         10.38          122.80     1001.0   \n",
       "1          1        20.57         17.77          132.90     1326.0   \n",
       "2          1        19.69         21.25          130.00     1203.0   \n",
       "3          1        11.42         20.38           77.58      386.1   \n",
       "4          1        20.29         14.34          135.10     1297.0   \n",
       "\n",
       "   smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
       "0          0.11840           0.27760          0.3001              0.14710   \n",
       "1          0.08474           0.07864          0.0869              0.07017   \n",
       "2          0.10960           0.15990          0.1974              0.12790   \n",
       "3          0.14250           0.28390          0.2414              0.10520   \n",
       "4          0.10030           0.13280          0.1980              0.10430   \n",
       "\n",
       "   symmetry_mean  ...  radius_worst  texture_worst  perimeter_worst  \\\n",
       "0         0.2419  ...         25.38          17.33           184.60   \n",
       "1         0.1812  ...         24.99          23.41           158.80   \n",
       "2         0.2069  ...         23.57          25.53           152.50   \n",
       "3         0.2597  ...         14.91          26.50            98.87   \n",
       "4         0.1809  ...         22.54          16.67           152.20   \n",
       "\n",
       "   area_worst  smoothness_worst  compactness_worst  concavity_worst  \\\n",
       "0      2019.0            0.1622             0.6656           0.7119   \n",
       "1      1956.0            0.1238             0.1866           0.2416   \n",
       "2      1709.0            0.1444             0.4245           0.4504   \n",
       "3       567.7            0.2098             0.8663           0.6869   \n",
       "4      1575.0            0.1374             0.2050           0.4000   \n",
       "\n",
       "   concave points_worst  symmetry_worst  fractal_dimension_worst  \n",
       "0                0.2654          0.4601                  0.11890  \n",
       "1                0.1860          0.2750                  0.08902  \n",
       "2                0.2430          0.3613                  0.08758  \n",
       "3                0.2575          0.6638                  0.17300  \n",
       "4                0.1625          0.2364                  0.07678  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['diagnosis'] = df['diagnosis'].map({'M':1,'B':0})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "_cell_guid": "1390898b-a338-7395-635f-6e1c216861e6"
   },
   "outputs": [],
   "source": [
    "trainset, testset = train_test_split(df, test_size = 0.2, random_state=2, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train = trainset['diagnosis']\n",
    "X_train = trainset.drop('diagnosis',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_test = testset['diagnosis']\n",
    "X_test = testset.drop('diagnosis',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>symmetry_mean</th>\n",
       "      <th>fractal_dimension_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>560</th>\n",
       "      <td>14.05</td>\n",
       "      <td>27.15</td>\n",
       "      <td>91.38</td>\n",
       "      <td>600.4</td>\n",
       "      <td>0.09929</td>\n",
       "      <td>0.11260</td>\n",
       "      <td>0.04462</td>\n",
       "      <td>0.04304</td>\n",
       "      <td>0.1537</td>\n",
       "      <td>0.06171</td>\n",
       "      <td>...</td>\n",
       "      <td>15.30</td>\n",
       "      <td>33.17</td>\n",
       "      <td>100.20</td>\n",
       "      <td>706.7</td>\n",
       "      <td>0.1241</td>\n",
       "      <td>0.22640</td>\n",
       "      <td>0.1326</td>\n",
       "      <td>0.10480</td>\n",
       "      <td>0.2250</td>\n",
       "      <td>0.08321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>428</th>\n",
       "      <td>11.13</td>\n",
       "      <td>16.62</td>\n",
       "      <td>70.47</td>\n",
       "      <td>381.1</td>\n",
       "      <td>0.08151</td>\n",
       "      <td>0.03834</td>\n",
       "      <td>0.01369</td>\n",
       "      <td>0.01370</td>\n",
       "      <td>0.1511</td>\n",
       "      <td>0.06148</td>\n",
       "      <td>...</td>\n",
       "      <td>11.68</td>\n",
       "      <td>20.29</td>\n",
       "      <td>74.35</td>\n",
       "      <td>421.1</td>\n",
       "      <td>0.1030</td>\n",
       "      <td>0.06219</td>\n",
       "      <td>0.0458</td>\n",
       "      <td>0.04044</td>\n",
       "      <td>0.2383</td>\n",
       "      <td>0.07083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>19.18</td>\n",
       "      <td>22.49</td>\n",
       "      <td>127.50</td>\n",
       "      <td>1148.0</td>\n",
       "      <td>0.08523</td>\n",
       "      <td>0.14280</td>\n",
       "      <td>0.11140</td>\n",
       "      <td>0.06772</td>\n",
       "      <td>0.1767</td>\n",
       "      <td>0.05529</td>\n",
       "      <td>...</td>\n",
       "      <td>23.36</td>\n",
       "      <td>32.06</td>\n",
       "      <td>166.40</td>\n",
       "      <td>1688.0</td>\n",
       "      <td>0.1322</td>\n",
       "      <td>0.56010</td>\n",
       "      <td>0.3865</td>\n",
       "      <td>0.17080</td>\n",
       "      <td>0.3193</td>\n",
       "      <td>0.09221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>13.81</td>\n",
       "      <td>23.75</td>\n",
       "      <td>91.56</td>\n",
       "      <td>597.8</td>\n",
       "      <td>0.13230</td>\n",
       "      <td>0.17680</td>\n",
       "      <td>0.15580</td>\n",
       "      <td>0.09176</td>\n",
       "      <td>0.2251</td>\n",
       "      <td>0.07421</td>\n",
       "      <td>...</td>\n",
       "      <td>19.20</td>\n",
       "      <td>41.85</td>\n",
       "      <td>128.50</td>\n",
       "      <td>1153.0</td>\n",
       "      <td>0.2226</td>\n",
       "      <td>0.52090</td>\n",
       "      <td>0.4646</td>\n",
       "      <td>0.20130</td>\n",
       "      <td>0.4432</td>\n",
       "      <td>0.10860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>10.95</td>\n",
       "      <td>21.35</td>\n",
       "      <td>71.90</td>\n",
       "      <td>371.1</td>\n",
       "      <td>0.12270</td>\n",
       "      <td>0.12180</td>\n",
       "      <td>0.10440</td>\n",
       "      <td>0.05669</td>\n",
       "      <td>0.1895</td>\n",
       "      <td>0.06870</td>\n",
       "      <td>...</td>\n",
       "      <td>12.84</td>\n",
       "      <td>35.34</td>\n",
       "      <td>87.22</td>\n",
       "      <td>514.0</td>\n",
       "      <td>0.1909</td>\n",
       "      <td>0.26980</td>\n",
       "      <td>0.4023</td>\n",
       "      <td>0.14240</td>\n",
       "      <td>0.2964</td>\n",
       "      <td>0.09606</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     radius_mean  texture_mean  perimeter_mean  area_mean  smoothness_mean  \\\n",
       "560        14.05         27.15           91.38      600.4          0.09929   \n",
       "428        11.13         16.62           70.47      381.1          0.08151   \n",
       "198        19.18         22.49          127.50     1148.0          0.08523   \n",
       "203        13.81         23.75           91.56      597.8          0.13230   \n",
       "41         10.95         21.35           71.90      371.1          0.12270   \n",
       "\n",
       "     compactness_mean  concavity_mean  concave points_mean  symmetry_mean  \\\n",
       "560           0.11260         0.04462              0.04304         0.1537   \n",
       "428           0.03834         0.01369              0.01370         0.1511   \n",
       "198           0.14280         0.11140              0.06772         0.1767   \n",
       "203           0.17680         0.15580              0.09176         0.2251   \n",
       "41            0.12180         0.10440              0.05669         0.1895   \n",
       "\n",
       "     fractal_dimension_mean  ...  radius_worst  texture_worst  \\\n",
       "560                 0.06171  ...         15.30          33.17   \n",
       "428                 0.06148  ...         11.68          20.29   \n",
       "198                 0.05529  ...         23.36          32.06   \n",
       "203                 0.07421  ...         19.20          41.85   \n",
       "41                  0.06870  ...         12.84          35.34   \n",
       "\n",
       "     perimeter_worst  area_worst  smoothness_worst  compactness_worst  \\\n",
       "560           100.20       706.7            0.1241            0.22640   \n",
       "428            74.35       421.1            0.1030            0.06219   \n",
       "198           166.40      1688.0            0.1322            0.56010   \n",
       "203           128.50      1153.0            0.2226            0.52090   \n",
       "41             87.22       514.0            0.1909            0.26980   \n",
       "\n",
       "     concavity_worst  concave points_worst  symmetry_worst  \\\n",
       "560           0.1326               0.10480          0.2250   \n",
       "428           0.0458               0.04044          0.2383   \n",
       "198           0.3865               0.17080          0.3193   \n",
       "203           0.4646               0.20130          0.4432   \n",
       "41            0.4023               0.14240          0.2964   \n",
       "\n",
       "     fractal_dimension_worst  \n",
       "560                  0.08321  \n",
       "428                  0.07083  \n",
       "198                  0.09221  \n",
       "203                  0.10860  \n",
       "41                   0.09606  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "45dac047-52fb-b847-a521-fa6883ebd5f6"
   },
   "source": [
    "### Solutions 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DG\\miniconda3\\envs\\py38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(max_iter=1000)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_model=LogisticRegression(max_iter=1000)\n",
    "lr_model.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy : 96.044%\n"
     ]
    }
   ],
   "source": [
    "# Training the model \n",
    "train_predictions = lr_model.predict(X_train)\n",
    "train_accuracy = metrics.accuracy_score(train_predictions,Y_train)\n",
    "\n",
    "print(\"Train Accuracy : %s\" % \"{0:.3%}\".format(train_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9604395604395605"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_model.score(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy : 92.982%\n"
     ]
    }
   ],
   "source": [
    "# Testing the model\n",
    "test_predictions = lr_model.predict(X_test)\n",
    "test_accuracy = metrics.accuracy_score(test_predictions,Y_test)\n",
    "print(\"Test accuracy : %s\" % \"{0:.3%}\".format(test_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### $\\Rightarrow:$ Not overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decision Tree model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier()"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt_model = DecisionTreeClassifier()\n",
    "dt_model.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 100.000%\n"
     ]
    }
   ],
   "source": [
    "# Training the model \n",
    "train_predictions = dt_model.predict(X_train)\n",
    "train_accuracy = metrics.accuracy_score(train_predictions,Y_train)\n",
    "\n",
    "print(\"Accuracy : %s\" % \"{0:.3%}\".format(train_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy : 91.228%\n"
     ]
    }
   ],
   "source": [
    "# Testing the model\n",
    "test_predictions = dt_model.predict(X_test)\n",
    "test_accuracy = metrics.accuracy_score(test_predictions,Y_test)\n",
    "print(\"Test accuracy : %s\" % \"{0:.3%}\".format(test_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### $\\Rightarrow:$ Overfitting slightly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solutions 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['radius_mean','perimeter_mean','area_mean','compactness_mean','concave points_mean']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(max_iter=1000)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_model=LogisticRegression(max_iter=1000)\n",
    "lr_model.fit(X_train[features], Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy : 90.330%\n"
     ]
    }
   ],
   "source": [
    "# Training the model \n",
    "train_predictions = lr_model.predict(X_train[features])\n",
    "train_accuracy = metrics.accuracy_score(train_predictions,Y_train)\n",
    "print(\"Train Accuracy : %s\" % \"{0:.3%}\".format(train_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy : 87.719%\n"
     ]
    }
   ],
   "source": [
    "# Testing the model\n",
    "test_predictions = lr_model.predict(X_test[features])\n",
    "test_accuracy = metrics.accuracy_score(test_predictions,Y_test)\n",
    "print(\"Test accuracy : %s\" % \"{0:.3%}\".format(test_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier()"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt_model = DecisionTreeClassifier()\n",
    "dt_model.fit(X_train[features], Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 100.000%\n"
     ]
    }
   ],
   "source": [
    "# Training the model \n",
    "train_predictions = dt_model.predict(X_train[features])\n",
    "train_accuracy = metrics.accuracy_score(train_predictions,Y_train)\n",
    "print(\"Accuracy : %s\" % \"{0:.3%}\".format(train_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy : 88.596%\n"
     ]
    }
   ],
   "source": [
    "# Testing the model\n",
    "test_predictions = dt_model.predict(X_test[features])\n",
    "test_accuracy = metrics.accuracy_score(test_predictions,Y_test)\n",
    "print(\"Test accuracy : %s\" % \"{0:.3%}\".format(test_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (Optional) 4.: Write own logistic regression class\n",
    "\n",
    "Write a class that has the following methods:\n",
    "\n",
    "- fit(X,Y): Should fit the model weights using feature matrix X and label vector y. Implement gradient descent to find a solution for a suitable w-vector.\n",
    "\n",
    "- predict(X): Should make predictions label predictions for X.\n",
    "\n",
    "- score(X,Y): Should make label predictions on X, and compute accuracy using the label information Y and the predictions.\n",
    "\n",
    "- train and evaluate your model on the wine dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and preprocess the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_wine\n",
    "from sklearn.metrics import log_loss \n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y = load_wine(return_X_y=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.hstack([np.ones((X.shape[0], 1)), X])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recap: Gradient:\n",
    "---\n",
    "$\\nabla_{\\mathbf w} J(\\mathbf w) = \\frac{1}{N}\\mathbf X^T(\\sigma(\\mathbf X \\mathbf w)-\\mathbf y)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement the sigmoid function - Warning: Might encounter overflow error\n",
    "def sigmoid(z):\n",
    "    return (1 / (1 + np.exp(-z)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.special import expit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is a Binary Logistic Regressor that uses Gradient Descent for learning the best fitting weights\n",
    "class BinaryLogisticRegressor():\n",
    "    \n",
    "    # Should store the positive class and its weights\n",
    "    def __init__(self, pos_class=None):\n",
    "        self.w = None\n",
    "        self.pos_class = pos_class\n",
    "    \n",
    "    # Implement GD using The formula above\n",
    "    def fit(self, X, Y, n_epochs=1000, alpha=0.001):\n",
    "        self.w = np.random.rand(X.shape[1],1)\n",
    "        loss = []\n",
    "        \n",
    "        for i in range(n_epochs):        \n",
    "            # Compute the gradient\n",
    "            delta_J = (1/len(X)) * np.dot(X.T, (expit(np.dot(X,self.w)) - Y[:,np.newaxis]))\n",
    "            \n",
    "            # Do the update\n",
    "            self.w = self.w - alpha * delta_J\n",
    "            \n",
    "            # store the lossin loss array (optional)\n",
    "            loss.append(log_loss(Y, expit(np.dot(X,self.w))))\n",
    "            \n",
    "    def predict(self, X):\n",
    "        # predict\n",
    "        predictions = expit(np.dot(X,self.w))\n",
    "        return np.round(predictions)\n",
    "    \n",
    "    def score(self, X, Y):\n",
    "        predictions = self.predict(X)\n",
    "        accuracy_score = np.sum(predictions == Y[:,np.newaxis]) / X.shape[0]\n",
    "        \n",
    "        return accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_2_class_dataset(X, Y, pos_class_id):\n",
    "    \n",
    "        class_1_ids = np.where(Y == pos_class_id)[0]\n",
    "        class_0_ids = np.where(Y != pos_class_id)[0]\n",
    "        \n",
    "        X_1 = X[class_1_ids]\n",
    "        X_0 = X[class_0_ids]\n",
    "        \n",
    "        Y_1 = np.ones(len(Y[class_1_ids])) \n",
    "        Y_0 = np.zeros(len(Y[class_0_ids]))\n",
    "    \n",
    "        X = np.concatenate([X_1, X_0], axis=0)\n",
    "        Y = np.concatenate([Y_1, Y_0])\n",
    "    \n",
    "        shuffled_indices = np.random.permutation(X.shape[0])\n",
    "    \n",
    "        return X[shuffled_indices], Y[shuffled_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiClassLogisticRegression():\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.models = None\n",
    "        \n",
    "    def fit(self, X, Y, n_epochs=2):\n",
    "        \n",
    "        self.n_epochs = n_epochs\n",
    "        \n",
    "        # 1. Get k unique labels\n",
    "        # 2  Create array to store k model weights \n",
    "        # 3. Get unique, class-dependent datasets\n",
    "        # 4. For each unique class:\n",
    "            # Create a binary dataset\n",
    "            # Create binary classifier\n",
    "            # Train binary classifier\n",
    "        # 5. Store model weights\n",
    "        \n",
    "        self.num_features = X.shape[1]\n",
    "        self.unique_classes = np.unique(Y)\n",
    "        \n",
    "        # Create array to store model weights\n",
    "        self.models = np.zeros((len(self.unique_classes), self.num_features))\n",
    "        \n",
    "        for i, pos_cls in enumerate(self.unique_classes):\n",
    "            \n",
    "            # Create unique dataset\n",
    "            X_tmp, Y_tmp = get_2_class_dataset(X, Y, pos_cls)\n",
    "            \n",
    "            # Create binary classifier\n",
    "            tmp_model = BinaryLogisticRegressor(pos_cls)\n",
    "            \n",
    "            # Train binary classifier\n",
    "            tmp_model.fit(X_tmp, Y_tmp, n_epochs)\n",
    "            \n",
    "            # Store model weights\n",
    "            self.models[i][:,np.newaxis] += tmp_model.w[:]\n",
    "            \n",
    "    def predict(self, X):\n",
    "        # Create empty prediction table:\n",
    "        \n",
    "        # First Dimension represents classifiers\n",
    "        # Second Dimension represents points\n",
    "        # Third Dimension represents class scores, first entry is prob. score for class 1, second class 0\n",
    "        predictions = np.zeros((len(self.unique_classes), 2, X.shape[0]))\n",
    "        \n",
    "        # Do a prediction for every classifier\n",
    "        for i, weights in enumerate(self.models):\n",
    "            \n",
    "            # Probability score for class 1\n",
    "            predictions[i][0][:,np.newaxis] += expit(np.dot(X, weights[:,np.newaxis]))\n",
    "            \n",
    "            # Probability score for class 2\n",
    "            predictions[i][1][:,np.newaxis] += 1-expit(np.dot(X, weights[:,np.newaxis]))\n",
    "            \n",
    "        # final predictions are is the argmax over classifier probability scores for class 1\n",
    "        final_predictions = np.argmax(predictions[:,0,:], axis=0)\n",
    "        \n",
    "        return final_predictions\n",
    "            \n",
    "    def score(self, X, Y):\n",
    "        \n",
    "        predictions = self.predict(X)\n",
    "        \n",
    "        correctly_predicted = np.sum(predictions == Y) \n",
    "        \n",
    "        return correctly_predicted / X.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "mclr = MultiClassLogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "mclr.fit(X,Y, 3000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = mclr.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6741573033707865"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mclr.score(X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mclr.models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "_change_revision": 416,
  "_is_fork": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
