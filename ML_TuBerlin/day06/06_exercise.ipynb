{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 6: Feature Engineering and Model Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Theory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1: MC\n",
    "Multiple answers are possible.\n",
    "\n",
    "**A regularized model has**\n",
    " - [ ] lower bias\n",
    " - [x] lower variance ; variance를 줄이기 위해 쓰는 기법임\n",
    " - [x] higher bias ; 트레이드 오프 관계에 의해서\n",
    " - [ ] higher variance\n",
    "\n",
    "**Which of the following Regularization techniques can be used for feature selection?**\n",
    " - [x] L1 ; 강의노트 3.2절 내용\n",
    " - [ ] L2\n",
    " - [ ] Early stopping\n",
    " - [ ] All of the above\n",
    "\n",
    "**Standardizing the training data by $\\frac{x-\\mu}{\\sigma}$ can decrease model performance if**\n",
    " - [ ] the data is centered\n",
    " - [x] the data is sparse ; 강의노트 3.1절 내용\n",
    " - [x] the data has outliers ; 강의노트 3.1절 내용\n",
    " - [ ] All of the above\n",
    "\n",
    "**How should you standardize (assuming `StandardScaler`) your test data before evaluating performance?**\n",
    " - [ ] not at all\n",
    " - [x] using the mean and variance computed from the training data ; 강의노트 3.1절 내용\n",
    " - [ ] by recomputing the mean and variance for the test data\n",
    " - [ ] All of the above\n",
    "\n",
    "**CrossValidation**\n",
    " - [ ] the number of folds determines how often the score is computed during cross validation\n",
    " - [x] the cross validated score is reported as the score average of all splits ; 평균 사용\n",
    " - [ ] when using KFold cross validation, every fold contains data of all classes\n",
    " - [ ] All of the above\n",
    "\n",
    "**Consider binary classification. A model that always returns 1 as its predicted class label, is more likely to have**\n",
    " - [ ] low accuracy\n",
    " - [ ] low precision\n",
    " - [ ] high recall\n",
    " - [x] All of the above ; 항상 1로만 예측한다면? [ref](https://sumniya.tistory.com/26)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Optional] Bias-variance decomposition for Regression\n",
    "Proof that for the Mean-squared error, we have\n",
    "- $Err[(y - \\hat f(x;D))^2] =  Bias(\\hat f(x))^2 + Var(\\hat f(x))$,\n",
    " \n",
    "where Err denotes the Expectation of the MSE w.r.t to the data distribution.\n",
    "\n",
    ">Note: If you are interested, you can also compute the Bias-variance decomposition for a classification error."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Programming\n",
    "In the programming exercises, we are going to work on the speeddating dataset from the lecture. \n",
    "\n",
    "For that, you are given the preprocessing pipeline presented there:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>has_null</th>\n",
       "      <th>wave</th>\n",
       "      <th>age</th>\n",
       "      <th>age_o</th>\n",
       "      <th>d_age</th>\n",
       "      <th>samerace</th>\n",
       "      <th>importance_same_race</th>\n",
       "      <th>importance_same_religion</th>\n",
       "      <th>pref_o_attractive</th>\n",
       "      <th>pref_o_sincere</th>\n",
       "      <th>...</th>\n",
       "      <th>d_concerts</th>\n",
       "      <th>d_music</th>\n",
       "      <th>d_shopping</th>\n",
       "      <th>d_yoga</th>\n",
       "      <th>d_interests_correlate</th>\n",
       "      <th>d_expected_happy_with_sd_people</th>\n",
       "      <th>d_expected_num_interested_in_me</th>\n",
       "      <th>d_expected_num_matches</th>\n",
       "      <th>d_like</th>\n",
       "      <th>d_guess_prob_liked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6083</th>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>25</td>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>[9-10]</td>\n",
       "      <td>[9-10]</td>\n",
       "      <td>[6-8]</td>\n",
       "      <td>[6-8]</td>\n",
       "      <td>[0-0.33]</td>\n",
       "      <td>[0-4]</td>\n",
       "      <td>[0-3]</td>\n",
       "      <td>[3-5]</td>\n",
       "      <td>[6-8]</td>\n",
       "      <td>[5-6]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2639</th>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>27</td>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>...</td>\n",
       "      <td>[0-5]</td>\n",
       "      <td>[6-8]</td>\n",
       "      <td>[0-5]</td>\n",
       "      <td>[0-5]</td>\n",
       "      <td>[-1-0]</td>\n",
       "      <td>[7-10]</td>\n",
       "      <td>[0-3]</td>\n",
       "      <td>[5-18]</td>\n",
       "      <td>[6-8]</td>\n",
       "      <td>[7-10]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4884</th>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>36</td>\n",
       "      <td>25</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>20</td>\n",
       "      <td>15</td>\n",
       "      <td>...</td>\n",
       "      <td>[9-10]</td>\n",
       "      <td>[9-10]</td>\n",
       "      <td>[9-10]</td>\n",
       "      <td>[6-8]</td>\n",
       "      <td>[0.33-1]</td>\n",
       "      <td>[7-10]</td>\n",
       "      <td>[0-3]</td>\n",
       "      <td>[3-5]</td>\n",
       "      <td>[9-10]</td>\n",
       "      <td>[7-10]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 120 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      has_null  wave  age  age_o  d_age  samerace  importance_same_race  \\\n",
       "6083         1    15   25     26      1         0                     1   \n",
       "2639         1     9   27     28      1         0                     3   \n",
       "4884         1    13   36     25     11         0                     5   \n",
       "\n",
       "      importance_same_religion  pref_o_attractive  pref_o_sincere  ...  \\\n",
       "6083                         5                 10              10  ...   \n",
       "2639                         9                 14              14  ...   \n",
       "4884                         5                 20              15  ...   \n",
       "\n",
       "      d_concerts  d_music  d_shopping  d_yoga  d_interests_correlate  \\\n",
       "6083      [9-10]   [9-10]       [6-8]   [6-8]               [0-0.33]   \n",
       "2639       [0-5]    [6-8]       [0-5]   [0-5]                 [-1-0]   \n",
       "4884      [9-10]   [9-10]      [9-10]   [6-8]               [0.33-1]   \n",
       "\n",
       "      d_expected_happy_with_sd_people  d_expected_num_interested_in_me  \\\n",
       "6083                            [0-4]                            [0-3]   \n",
       "2639                           [7-10]                            [0-3]   \n",
       "4884                           [7-10]                            [0-3]   \n",
       "\n",
       "      d_expected_num_matches  d_like  d_guess_prob_liked  \n",
       "6083                   [3-5]   [6-8]               [5-6]  \n",
       "2639                  [5-18]   [6-8]              [7-10]  \n",
       "4884                   [3-5]  [9-10]              [7-10]  \n",
       "\n",
       "[3 rows x 120 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.compose import make_column_selector, make_column_transformer\n",
    "from sklearn.preprocessing import StandardScaler, OrdinalEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "def maybe_convert_to_int(col):\n",
    "    try:\n",
    "        col = pd.to_numeric(col.replace('?', -1), errors='raise').astype(int)\n",
    "    except Exception as e:\n",
    "        return col\n",
    "    return col\n",
    "\n",
    "df = pd.read_csv('data/speeddating.csv', low_memory=False)\n",
    "df = df.apply(maybe_convert_to_int, axis=0)\n",
    "\n",
    "cat_cols = make_column_selector(dtype_include=object)\n",
    "num_cols = make_column_selector(dtype_include=np.number)\n",
    "\n",
    "num_pipe = make_pipeline(SimpleImputer(missing_values=-1, strategy='mean'), StandardScaler())\n",
    "cat_pipe = make_pipeline(OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=np.nan))\n",
    "\n",
    "ct = make_column_transformer(\n",
    "  (num_pipe, num_cols),\n",
    "  (cat_pipe, cat_cols),\n",
    ")\n",
    "\n",
    "# ct.transform(Xtrain) will change the column order to num_cols(df) + cat_cols(df)\n",
    "# we change it beforehand, so that ytrain will have same column order after calling train_test_split\n",
    "df = df[num_cols(df) + cat_cols(df)]\n",
    "df = df.drop(['decision', 'decision_o'], axis=1)\n",
    "Xtrain, Xtest, ytrain, ytest = train_test_split(df.drop('match', axis=1), df['match'])\n",
    "Xtrain.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "121"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8378 entries, 0 to 8377\n",
      "Columns: 121 entries, has_null to d_guess_prob_liked\n",
      "dtypes: int32(62), object(59)\n",
      "memory usage: 5.8+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Optional] Sklearn Feature Selection using RandomForest\n",
    "Repeat the Feature Selection Exercise from the lecture (using SelectFromModel) but with RandomForestClassifier using the train and test split, as well as the column transformer defined in the cell above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1: Feature Selection\n",
    "---\n",
    "Look at Algorithm 2 on page 7 of the paper [Feature Selection Based on L1-Norm SupportVector Machine and Effective Recognition Systemfor Parkinson’s Disease Using Voice Recordings](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8672565)\n",
    "\n",
    "> The goal of this exercise is to implement a similar pipeline but for the speeddating dataset from the lecture. You can download it at\n",
    "https://www.openml.org/d/40536. \n",
    "\n",
    "`We are going to repeatedly perform feature selection, using a L1 penalized SVM, of which the parameter 'C' has been optimized using GridSearchCV, until the feature set can no longer be reduced.`\n",
    "\n",
    "For this purpose, you should ...\n",
    "\n",
    "1. Run GridSearchCV to pick the best 'C' for your LinearSVC. You can use for example param_grid = ```\n",
    "[{'C': [0.01, 0.1, 1., 10.]}]```\n",
    "2. Fit the ```LinearSVC(penalty='l1', dual=False)``` using the current set of features (do not forget to reduce your training dataset and apply the preprocessing again)\n",
    "3. Reduce the number of features using ```SelectFromModel(lsvc, prefit=True)```'s  method\n",
    "4. Repeat until the number of returned features does not change or for a maximum number of iterations, e.g. 10\n",
    "\n",
    "For debugging, you can use only a subset of the features, e.g.\n",
    "```selected_features = ['attractive_o', 'funny_o', 'shared_interests_o', 'attractive_partner']``` to start with. But note that this set will not be further reduced by SelectFromModel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len = 46\n",
      "len = 46\n",
      "len = 46\n",
      "len = 46\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "param_grid = [{'C': [0.01, 0.1, 1., 10.]}]\n",
    "\n",
    "selected_features = np.array(Xtrain.columns)\n",
    "previous_number_of_features = np.inf\n",
    "max_it = 10\n",
    "i = 0\n",
    "iteration_num_features_not_changed  = 0\n",
    "estimator = LinearSVC(penalty='l1', dual=False, max_iter=5000)\n",
    "\n",
    "while i < max_it and iteration_num_features_not_changed < 2:\n",
    "    iteration_num_features_not_changed += int(previous_number_of_features == len(selected_features))\n",
    "    if previous_number_of_features != len(selected_features):\n",
    "        iteration_num_features_not_changed = 0\n",
    "    previous_number_of_features = len(selected_features)\n",
    "\n",
    "    # Grid Search best params\n",
    "    Xtrain = Xtrain[selected_features]\n",
    "    X = ct.fit_transform(Xtrain)\n",
    "    clf = GridSearchCV(estimator, param_grid).fit(X, ytrain)\n",
    "\n",
    "    # use best params to do feature selection\n",
    "    estimator = LinearSVC(**clf.best_params_, penalty='l1', dual=False).fit(X, ytrain)\n",
    "    sfm = SelectFromModel(estimator, prefit=True)\n",
    "    mask = sfm.get_support()\n",
    "\n",
    "    # reduce features\n",
    "    selected_features = np.array(Xtrain.columns)[mask]\n",
    "\n",
    "    print(f'len = {len(selected_features)}')\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 1\n",
      "1 2\n",
      "None None\n"
     ]
    }
   ],
   "source": [
    "# *, ** 사용법 설명\n",
    "def f(arg1='str', arg2=1):\n",
    "    print(arg1, arg2)\n",
    "\n",
    "def g(a,b):\n",
    "    print(a,b)\n",
    "\n",
    "t = (1,2)\n",
    "d = {'b': 1,\n",
    "    'a': 2}\n",
    "print(g(**d), g(*t))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Optional] Hyperparameter optimization and Cross-validation\n",
    "Having implemented the Feature Selection Algorithm, you can implement the whole proposed system, i.e. Implement Algorithm 1 on page 4 for our dataset. \n",
    "\n",
    "You can and should modify/simplify it whenever necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len = 105\n",
      "len = 104\n",
      "len = 104\n",
      "len = 104\n",
      "mean_test_score = 0.8491646778042959\n",
      "best performance = 0.8663484486873508\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.compose import make_column_selector, make_column_transformer\n",
    "from sklearn.preprocessing import StandardScaler, OrdinalEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "\n",
    "\"\"\"Step 1: Preprocessing \"\"\"\n",
    "def maybe_convert_to_int(col):\n",
    "    try:\n",
    "        col = pd.to_numeric(col.replace('?', -1), errors='raise').astype(int)\n",
    "    except Exception as e:\n",
    "        return col\n",
    "    return col\n",
    "\n",
    "\n",
    "df = pd.read_csv('data/speeddating.csv', low_memory=False)\n",
    "df = df.apply(maybe_convert_to_int, axis=0)\n",
    "\n",
    "cat_cols = make_column_selector(dtype_include=object)\n",
    "num_cols = make_column_selector(dtype_include=np.number)\n",
    "\n",
    "num_pipe = make_pipeline(SimpleImputer(missing_values=-1, strategy='mean'), StandardScaler())\n",
    "cat_pipe = make_pipeline(OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=np.nan))\n",
    "\n",
    "ct = make_column_transformer(\n",
    "  (num_pipe, num_cols),\n",
    "  (cat_pipe, cat_cols),\n",
    ")\n",
    "\n",
    "# ct.transform(Xtrain) will change the column order to num_cols(df) + cat_cols(df)\n",
    "# we change it beforehand, so that ytrain will have same column order after calling train_test_split\n",
    "df = df[num_cols(df) + cat_cols(df)]\n",
    "df = df.drop(['decision', 'decision_o'], axis=1)\n",
    "Xtrain, Xtest, ytrain, ytest = train_test_split(df.drop('match', axis=1), df['match'])\n",
    "\n",
    "\"\"\" Step 2: Feature Selection \"\"\"\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "a = 1\n",
    "\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "param_grid = [{'C': [0.01, 0.1,]}]\n",
    "selected_features = np.array(Xtrain.columns)\n",
    "\n",
    "prev = -np.inf\n",
    "idle = 0\n",
    "\n",
    "max_it = 10\n",
    "i = 0\n",
    "\n",
    "estimator = LinearSVC(penalty='l1', dual=False, max_iter=5000)\n",
    "\n",
    "while i < max_it and idle < 2:\n",
    "\n",
    "    # Grid Search best params\n",
    "    Xtrain = Xtrain[selected_features]\n",
    "    X = ct.fit_transform(Xtrain)\n",
    "    clf = GridSearchCV(estimator, param_grid).fit(X, ytrain)\n",
    "\n",
    "    # use best params to do feature selection\n",
    "    estimator = LinearSVC(**clf.best_params_, penalty='l1', dual=False, max_iter=5000).fit(X, ytrain)\n",
    "    sfm = SelectFromModel(estimator, prefit=True)\n",
    "    mask = sfm.get_support()\n",
    "\n",
    "    # reduce features\n",
    "    selected_features = np.array(Xtrain.columns)[mask]\n",
    "    idle += 1 if prev == len(selected_features) else 0\n",
    "\n",
    "    prev = len(selected_features)\n",
    "    print(f'len = {len(selected_features)}')\n",
    "    i += 1\n",
    "\n",
    "\"\"\" Steps 3-7: [Optional] \"\"\"\n",
    "\n",
    "\n",
    "# Step 3: 10-fold cross validation split\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "kf = KFold(n_splits=10)\n",
    "\n",
    "# Step 4: train classifier\n",
    "cv_score = cross_val_score(estimator=estimator, X=X, y=ytrain, cv=kf)\n",
    "\n",
    "# Step 5: cross_val_score: test set\n",
    "test_scores = cross_val_score(estimator, ct.transform(Xtest[selected_features]), ytest)\n",
    "\n",
    "# Step 6: cross_val_score.mean()\n",
    "print(f'mean_test_score = {test_scores.mean()}')\n",
    "# Step 7:\n",
    "print(f'best performance = {max(test_scores)}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
