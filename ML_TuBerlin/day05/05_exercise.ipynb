{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 5: Support Vector Machines and RandomForests\n",
    "## Theory\n",
    "### Task 1: Derivation of the dual problem\n",
    "---\n",
    "Derive the Dual formulation of the SVM optimization problem. I.e.\n",
    "\n",
    "Given \n",
    " - $\\underset{\\alpha}{max}\\big\\{ \\underset{w,b}{min}\\{ \\frac{1}{2}\\lVert w\\rVert^2 + \\sum_{i=1} \\alpha_i(1 - y_i(w^T\\Phi(x_i) + b)) \\} \\big\\}, \\alpha_i \\geq 0,$ for all $i=1,...,m$,\n",
    " \n",
    "show that a solution can be obtained by\n",
    " - $\\underset{\\alpha}{max} \\sum_i \\alpha_i - \\frac{1}{2} \\alpha_i\\alpha_jy_iy_j\\langle\\Phi(x_i), \\Phi(x_j)\\rangle$ \n",
    "\n",
    "subject to the constraints $\\mathbf{\\alpha} \\geq 0 $ and $\\sum_i\\alpha_iy_i = 0$. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Optional] Primal variables w,b from the dual solution\n",
    "---\n",
    "Show how the parameters $w$ and $b$ can be obtained from the solution of dual for predicting new points. Note: $b$ is tricky"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2: Hinge loss\n",
    "---\n",
    "The hinge loss is defined as \n",
    " - $l_{hinge}(y, g(x)) = max(0, 1-y_ig(x))$\n",
    "\n",
    "Show how we can inject it into the Soft Margin Primal Problem\n",
    "- $\\underset{w,b,\\xi}{min} \\frac{1}{2}\\lVert w \\rVert^2 + C \\sum_i \\xi_i$ s. t.\n",
    "\n",
    "$y_i(w^T\\Phi(x_i) + b) \\geq 1 - \\xi_i$ and $\\xi_i \\geq 0$.\n",
    "\n",
    "to remove the constraints completely."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Programming\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1: Sklearn Warmup using toy datasets\n",
    "---\n",
    "**Task 1 SVC**\n",
    " - Train one sklearn.svm.SVC (Support Vector Classifier) model on the wine-dataset for each predefined kernel.\n",
    " - You can get the dataset via sklearn.datasets.load_wine.\n",
    " - Split the dataset into train and test data and report the kernel that performs best on the test data using the sklearn.metrics.accuracy_score metric\n",
    " - plot the confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sklearn Warmup using toy datasets:\n",
    "---\n",
    "**Task 1 RandomForest**\n",
    " - Train one sklearn.ensemble.RandomForestRegressor model on the diabetes-dataset for each predefined criterion.\n",
    " - You can get the dataset via sklearn.datasets.load_diabetes.\n",
    " - Split the dataset into train and test data and report the criterion that performs best on the test data using the sklearn.metrics.r2_score metric\n",
    " - plot the predicted against the true values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** In the warmup, you do not have to do any preprocessing. We will cover data preprocessing(standardization, feature selection, etc.) in the next lecture.\n",
    "\n",
    "Similarly, you do not have to use cross validation or any sort of hyperparameter selection. You can for now use the default values of the estimators.\n",
    "The according methods will be covered in the next lecture as well.\n",
    "\n",
    "If your SVM is slow and your dataset not too big, scale data to [-1,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Optional] Multiclass classification\n",
    "---\n",
    "Apply the SVM to a multiclass classification problem of your choice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2: EEG Eye state dataset (Time series data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this exercise you will \n",
    "do classification on the EEG Eye state dataset. Sliding windows have already been applied to turn it into a supervised problem. You can familiarise yourself with it here: https://archive.ics.uci.edu/ml/datasets/EEG+Eye+State\n",
    "\n",
    "1. Load the data and labels and transform them into X, y in the format of sklearn toy datasets. (Tricky)\n",
    "\n",
    "```python\n",
    "from scipy.io import arff\n",
    "with open('data/eyes.arff', mode='r') as f:\n",
    "    # X, y = ...\n",
    "    # Xtrain, Xtest, ytrain, ytest = ... \n",
    "    pass\n",
    "```\n",
    "2. Fit a RandomForest Classifier and SVC on the data after splitting it into train- and testset.\n",
    "3. Report the best result. Can you tune the SVC to reach the performance of the random forest with default params?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data and compute train test splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare results, maybe tune SVC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Optional] Novelty detection using SVM\n",
    "---\n",
    "Novelty detection inspired by SVMs is done by finding the smalles enclosing sphere of the data, i.e. solving\n",
    " - $\\underset{R,c}{min} R^2$ subject to the constraints\n",
    " $\\lVert \\Phi(x_i)-c\\rVert^2 \\leq R^2$\n",
    "\n",
    "A point $x$ is then reported a novelty, if it exceeds a distance from the center:\n",
    "$f(x) = sign(\\lVert \\Phi(x_i)-c\\rVert - \\tau)$\n",
    " \n",
    "Familiarise yourself with the section on novelty detection via svms, by reading the corresponding section in the sklearn userguide\n",
    " - https://scikit-learn.org/stable/modules/outlier_detection.html#novelty-detection\n",
    "\n",
    "Pick a dataset from the Outlier Detection DataSets http://odds.cs.stonybrook.edu/ and try to find the outliers using sklearn.svm.OneClassSvm\n",
    "\n",
    "You can report your findings, either by comparison or using plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
