{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 8: Unsupervised Learning - Dimensionality Reduction\n",
    "## Theory\n",
    "### Task 1: LLE - optimizing reconstruction loss $l(W) = \\sum_{i=1}^t \\lVert x_i - \\sum_{j=1}^K W_{ij}x_j\\rVert^2$\n",
    "---\n",
    "The constrained weights that best reconstruct eacht data point from its neighbors can be computed in closed form.\n",
    "\n",
    "First, see Appendix A, page 9 in the [original LLE paper](http://www.cs.columbia.edu/~jebara/6772/papers/lleintro.pdf) and familiarize yourself with equations (3) and (4).\n",
    "\n",
    "Then the solution of the given least squares problem can be computed by means of the Lagrangian function, that we presented in the lecture. For that we rephrase the problem as follows:\n",
    "\n",
    " - $min\\ l(W) = min \\sum_{jk}w_jw_kC_{jk}$, where $C_{jk} = (x-\\nu_j)\\cdot (x-\\nu_k)$ subject to $\\sum_j w_j =1$\n",
    "\n",
    "Letting the Lagrangian $L(W, \\lambda) = f(W) + \\lambda g(W)$, first define $f(W)$, and $g(W)$ according to our minimization problem, and then try to solve the problem analytically. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Optional] Principal components are orthogonal\n",
    "---\n",
    "\n",
    "Show that the principal components, i.e. the eigenvectors of the covariance matrix $S=\\frac{1}{n}\\tilde X\\tilde X^T$ are orthogonal. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Programming\n",
    "### Task 1: Implementation of PCA\n",
    "---\n",
    "In this task you are asked to implement your own class PCA, that implements a subset of the functions in ```sklearn.decomposition.PCA class```. In particular, your class should implement a fit, transform, and inverse transform method. These should expect as an argument ```X```, a 2 dimensional numpy.ndarray. To compute the eigendecomposition of the covariance matrix of your centered data matrix```X```, you should use ```numpy.linalg.svd```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "class PCA:\n",
    "    def __init__(n_components=2):\n",
    "        self.n_components_ = n_components\n",
    "        \n",
    "    def fit(X):\n",
    "        # todo: implement\n",
    "        pass\n",
    "    def transform(X):\n",
    "        # todo: implement\n",
    "        pass\n",
    "    def inverse_transform(X):\n",
    "        # todo: implement\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Programming\n",
    "### [Optional] Extending PCA implementation\n",
    "---\n",
    "Extend your PCA implementation, such that\n",
    " 1. if n_components=None, then all principal components are used\n",
    " 2. it has attributes ```explained_variance_``` and ```explained_variance_ratio``` such that after fitting, these attributes return the same values as the reference implementation in ```sklearn.decomposition.PCA```."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Optional] Task 2: Visualize Mnist in 2D using t-SNE\n",
    "---\n",
    "Use sklearn.datasets.load_digits to load the Mnist dataset. Then,\n",
    "using ```sklearn.manifold.TSNE``` and/or ```sklearn.decomposition.PCA```, try to plot a picture that is close to \n",
    "<img src=\"img\\hw.png\" alt=\"Drawing\" style=\"width: 1024px;\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
